<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Concept: Filters</title>
    <link>https://forum.rebol.info/t/concept-filters/2000</link>
    <description>Filters are a means of incrementally transcoding data from source to brokered output (bytes/binary! or characters/text!). A goal is to provide a standard API for transcoding that can be implemented and used as efficiently as possible (e.g. extracting a portion of encoded data without extracting the whole; native transcoders for Deflate). A filter could conceivably be implemented as a distinct type that has object-like properties (as the PORT! type does) and could thus be acted upon by the appropriate Rebol actors (COPY/SKIP/NEXT/TAIL, etc.).

*I&#39;ve alluded to a similar idea in [an earlier post](https://forum.rebol.info/t/semantics-of-port-s-vs-streams-vs-iterators/1689/4?u=rgchris), however this concept is more focussed on transcoding one series of numbers/characters to another. Filters are NOT scanners/tokenizers/lexers.*

A filter source can be:

* BINARY! or TEXT! values
* PORT! values that stream BINARY! or TEXT! (including files/network resources)
* filter values (i.e. filters can be layered)

Examples of filter types:

* Retrieves binary contained within a file/network resource
* Decodes text encoded as UTF-8, UTF-16, ISO-8859-1, CP-1252, etc. (or even unspecified using something like Chardet)
* Decodes binary compressed per Deflate, LZW, etc.
* Decodes binary encoded as &#39;text&#39; per Base64, Ascii85, Hexadecimal, etc.
* Decrypts binary encrypted per e.g. Rebol 2 ENCLOAK/DECLOAK (but obviously more)
* Decodes text encoded mostly literally but with escape sequences, e.g. JSON strings, Rebol strings, XML/HTML data sequences/attribute values

Filters should have at least the following capabilities:

* Copy all encoded data
* Copy part of the encoded data
* Skip part of the encoded data (Deflate could potentially iterate faster if it wasn&#39;t emitting simultaneously)

Filters should possibly have the following capabilities:

* BACK/HEAD/negative SKIP support
* TAKE/REMOVE/CLEAR as a means of clearing buffers

Functions that consume data should support filters as a pseudo-series type, e.g.

* Parse
* BINARY/READ (from Oldes/Rebol3)
* CONSUME (from [rgchris/bincode](https://forum.rebol.info/t/bincode/1863?u=rgchris))

Filter values are exhausted when:

* An end-of-content signal/delimiter has been found e.g. self-terminating formats such as Deflate; quote marks ending a JSON string
* A filter cap has been reached e.g. the filter has a specified length
* An unrecoverable error occurs (e.g. invalid UTF-8 sequences in strict mode; the &#39;g&#39; character in a hexadecimal stream)
* The source has been exhausted

It should be possible to recover the current source at the corresponding index within a filter value though this may require additional state info, e.g. in Deflate or Base64 where a byte within an encoding has information pertaining to more than one decoded byte

Filter algorithms can be native (e.g. Deflate tied to Zlib, UTF-8) or in user-mode (thus extensible).</description>
    
    <lastBuildDate>Thu, 05 Jan 2023 23:10:32 +0000</lastBuildDate>
    <category>Development</category>
    <atom:link href="https://forum.rebol.info/t/concept-filters/2000.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Concept: Filters</title>
        <dc:creator><![CDATA[rgchris]]></dc:creator>
        <description><![CDATA[
            <aside class="quote no-group" data-username="hostilefork" data-post="4" data-topic="2000">
<div class="title">
<div class="quote-controls"></div>
<img loading="lazy" alt="" width="24" height="24" src="https://forum.rebol.info/user_avatar/forum.rebol.info/hostilefork/48/421_2.png" class="avatar"> hostilefork:</div>
<blockquote>
<p>I'm curious about this distinction... why wouldn't a filter that takes in UTF-8 and produces a block of transcoded data be covered here? What's the missing capability?</p>
</blockquote>
</aside>
<p>I think it's ultimately scope creep. In my proposal in the other thread, I'd conceived as such a mechanism as tokenizing as well, but in hashing out many of the data points I've been considering, it just became too convoluted. I feel in isolating binary/text it's really a clean separation that lends well to optimization and doesn't fall into the Codec black box that I think is ultimately problematic.</p>
<aside class="quote no-group" data-username="hostilefork" data-post="4" data-topic="2000">
<div class="title">
<div class="quote-controls"></div>
<img loading="lazy" alt="" width="24" height="24" src="https://forum.rebol.info/user_avatar/forum.rebol.info/hostilefork/48/421_2.png" class="avatar"> hostilefork:</div>
<blockquote>
<p>The umbrella term I tend to myself use above "Filter"/"Codecs"/"Ports" is "Streaming".</p>
</blockquote>
</aside>
<p><em>'Filter'</em> is the term used in PDF and I think lends itself to this specific isolation. <em>'Streaming'</em> would apply, but could also be saved for more appropriate use, such as the mechanism for moving data in from external sources. And one can apply <em>filters</em> to a <em>stream</em>...</p>
<aside class="quote no-group" data-username="hostilefork" data-post="4" data-topic="2000">
<div class="title">
<div class="quote-controls"></div>
<img loading="lazy" alt="" width="24" height="24" src="https://forum.rebol.info/user_avatar/forum.rebol.info/hostilefork/48/421_2.png" class="avatar"> hostilefork:</div>
<blockquote>
<p>Maybe we could get examples worked up and see some contrast with how those would be done e.g. in C++ (with <a href="https://think-async.com/Asio/">Boost.Asio</a>) or in Conduit/Pipes/Machines/Streams of Haskell? I feel that really helped with UPARSE to drive the design from ideas that had already been worked out.</p>
</blockquote>
</aside>
<p>I'm still following through on my line of inquiry here and see if I can get some success in streamlining some of the <em>'Codec'</em> work I've been exploring. Certainly some of this thinking comes, again, from working a bit with Iterators in Javascript. I still think tokenization can be done in an iterative fashion as well, but that's a bit down the line.</p>
<hr>
<p>I'm inclined to think this concept offers something new and quite compelling that I don't see in these alternatives (or at least, <em>Pipes</em> would seem similar but I find the examples quite opaque). The ability to work through layered encoding in an incremental manner that would only place in memory the essential parts of a stream, and in a way that is really quite minimal in terms of its impact on the language. The mechanics for obtaining the stream are where they should be and it encourages a style of handling incoming data in a way that is incremental, precise and relatively non-blocking—180º from the traditional Rebol family model if nothing else.</p>
<p>Of course, it's easy to say so. Need to actually flex it a bit to back that up. And I haven't got to PostScript yet...</p>
          <p><a href="https://forum.rebol.info/t/concept-filters/2000/5">Read full topic</a></p>
        ]]></description>
        <link>https://forum.rebol.info/t/concept-filters/2000/5</link>
        <pubDate>Thu, 05 Jan 2023 20:33:44 +0000</pubDate>
        <guid isPermaLink="false">forum.rebol.info-post-2000-5</guid>
        <source url="https://forum.rebol.info/t/concept-filters/2000.rss">Concept: Filters</source>
      </item>
      <item>
        <title>Concept: Filters</title>
        <dc:creator><![CDATA[hostilefork]]></dc:creator>
        <description><![CDATA[
            <p>Related threads:</p>
<ul>
<li><a href="https://forum.rebol.info/t/streaming-mental-blocks-and-some-haskell-streaming-research/1325" class="inline-onebox">Streaming Mental Blocks, and some Haskell Streaming Research</a></li>
<li><a href="https://forum.rebol.info/t/streaming-survey-from-other-languages/1739" class="inline-onebox">"Streaming" Survey from Other Languages</a></li>
<li><a href="https://forum.rebol.info/t/parsing-giant-streams-without-consuming-tons-of-memory-how/1698" class="inline-onebox">Parsing Giant Streams Without Consuming Tons of Memory: How?</a></li>
</ul>
<hr>
<aside class="quote no-group quote-modified" data-username="rgchris" data-post="1" data-topic="2000">
<div class="title">
<div class="quote-controls"></div>
<img loading="lazy" alt="" width="24" height="24" src="https://forum.rebol.info/user_avatar/forum.rebol.info/rgchris/48/14_2.png" class="avatar"> rgchris:</div>
<blockquote>
<p>this concept is more focused on transcoding one series of numbers/characters to another. Filters are NOT scanners/tokenizers/lexers.</p>
</blockquote>
</aside>
<p>I'm curious about this distinction... why wouldn't a filter that takes in UTF-8 and produces a block of transcoded data be covered here?  What's the missing capability?</p>
<aside class="quote no-group" data-username="rgchris" data-post="1" data-topic="2000">
<div class="title">
<div class="quote-controls"></div>
<img loading="lazy" alt="" width="24" height="24" src="https://forum.rebol.info/user_avatar/forum.rebol.info/rgchris/48/14_2.png" class="avatar"> rgchris:</div>
<blockquote>
<p>A filter could conceivably be implemented as a distinct type that has object-like properties (as the PORT! type does) and could thus be acted upon by the appropriate Rebol actors (COPY/SKIP/NEXT/TAIL, etc.).</p>
</blockquote>
</aside>
<p>The umbrella term I tend to myself use above "Filter"/"Codecs"/"Ports" is "Streaming".  This is because of the use of the term in C++ and in Haskell in the cases I find interesting.  But even in Haskell it branches off into different models, such as <strong><a href="https://www.schoolofhaskell.com/school/advanced-haskell/conduit-overview">Conduit</a></strong>, <strong><a href="https://www.schoolofhaskell.com/user/Gabriel439/Pipes%20tutorial">Pipes</a></strong> and <strong><a href="https://statusfailed.com/blog/2014/09/02/practical-machines-in-60-seconds.html">Machines</a></strong></p>
<p>I'm glad you're putting down some concrete examples and experimenting with them.  Because if one stays fully general it gets hard to know what the limits are that would inform a useful design.</p>
<p>Maybe we could get examples worked up and see some contrast with how those would be done e.g. in C++ (with <a href="https://think-async.com/Asio/">Boost.Asio</a>) or in Conduit/Pipes/Machines/Streams of Haskell?  I feel that really helped with UPARSE to drive the design from ideas that had already been worked out.</p>
          <p><a href="https://forum.rebol.info/t/concept-filters/2000/4">Read full topic</a></p>
        ]]></description>
        <link>https://forum.rebol.info/t/concept-filters/2000/4</link>
        <pubDate>Thu, 05 Jan 2023 18:16:06 +0000</pubDate>
        <guid isPermaLink="false">forum.rebol.info-post-2000-4</guid>
        <source url="https://forum.rebol.info/t/concept-filters/2000.rss">Concept: Filters</source>
      </item>
      <item>
        <title>Concept: Filters</title>
        <dc:creator><![CDATA[rgchris]]></dc:creator>
        <description><![CDATA[
            <p>One interesting file format is that of <a href="http://site.xara.com/support/docs/webformat/spec/">Xara (XAR) vector images</a>. They consist of an eight-byte header followed by a collection of records. Records consist of two little-endian 32-bit integers denoting the record type and size followed by the record content. Presumably easy to traverse—however: the wrinkle here is that there is one record type that indicates that subsequent records are encoded in a single Deflate stream that terminates with both the end of the Deflate stream and a record type that indicates the end of the compressed section.</p>
<p>This is a simplified way of looking at it (each tag representing a whole record):</p>
<pre><code class="lang-nohighlight">---- regular byte stream ----
&lt;8-byte header&gt;
&lt;title&gt;
&lt;metadata&gt;
&lt;start-compressed-section&gt;
---- deflate compressed byte stream ----
&lt;thing&gt;
&lt;thing&gt;
...
&lt;end-compressed-section&gt;
---- regular byte stream ----
&lt;thing&gt;
&lt;thing&gt;
---- eof ----
</code></pre>
<p>This type of switch could be handled with filters.</p>
<pre><code class="lang-nohighlight">file-content: make filter! [
    source: open/direct %image.xar
]

content: file-content

consume content #{... magic number ...}

until [
    type: consume content 'unsigned-32-le
    size: consume content 'unsigned-32-le

    switch type [
        types/start-compressed-section [
            content: make filter! [
                type: 'deflate
                source: file-content
            ]
        ]

        types/end-compressed-section [
            assert [
                tail? content
            ]

            content: file-content
        ]
    ]

    ... record dispatcher ...

    type == types/end-of-file
]
</code></pre>
          <p><a href="https://forum.rebol.info/t/concept-filters/2000/3">Read full topic</a></p>
        ]]></description>
        <link>https://forum.rebol.info/t/concept-filters/2000/3</link>
        <pubDate>Thu, 05 Jan 2023 15:06:16 +0000</pubDate>
        <guid isPermaLink="false">forum.rebol.info-post-2000-3</guid>
        <source url="https://forum.rebol.info/t/concept-filters/2000.rss">Concept: Filters</source>
      </item>
      <item>
        <title>Concept: Filters</title>
        <dc:creator><![CDATA[rgchris]]></dc:creator>
        <description><![CDATA[
            <p>I'll spitball samples/test cases in replies. The example from the ports/streams/iterator posts was a layered encoding where an compressed encoding is in turn encoded as text:</p>
<pre><code class="lang-nohighlight">encoded: make filter! [
    ; implied type: 'text
    source: "start F3DI7!! end"
]

consume encoded "start"

encoded-ascii85: make filter! [
    type: 'ascii85
    source: encoded
]

encoded-deflate: make filter! [
    type: 'deflate
    source: encoded-ascii85
]

result: copy encoded-deflate

consume encoded " end"
=&gt; true
</code></pre>
<h2>Extracting from a large file</h2>
<pre><code class="lang-nohighlight">big-file: open/direct %big-file.txt

file-content: make filter! [
    ; implied type: 'stream
    source: big-file
]

copy/part skip file-content 1'000'000 25
</code></pre>
<p>As mentioned, ideally filter algorithms would have mechanisms to skip content without buffering, so you could do the following as fast as any other way of doing it:</p>
<pre><code class="lang-nohighlight">big-file: open/direct %big-file.txt

file-content-as-utf-8: make filter! [
    type: 'utf-8
    source: make filter! [
        ; implied type: 'stream
        source: big-file
    ]
]

copy/part skip file-content 1'000'000 25
; skips 1'000'000 UTF-8 characters without copying/buffering
</code></pre>
          <p><a href="https://forum.rebol.info/t/concept-filters/2000/2">Read full topic</a></p>
        ]]></description>
        <link>https://forum.rebol.info/t/concept-filters/2000/2</link>
        <pubDate>Thu, 05 Jan 2023 04:01:38 +0000</pubDate>
        <guid isPermaLink="false">forum.rebol.info-post-2000-2</guid>
        <source url="https://forum.rebol.info/t/concept-filters/2000.rss">Concept: Filters</source>
      </item>
      <item>
        <title>Concept: Filters</title>
        <dc:creator><![CDATA[rgchris]]></dc:creator>
        <description><![CDATA[
            <p>Filters are a means of incrementally transcoding data from source to brokered output (bytes/binary! or characters/text!). A goal is to provide a standard API for transcoding that can be implemented and used as efficiently as possible (e.g. extracting a portion of encoded data without extracting the whole; native transcoders for Deflate). A filter could conceivably be implemented as a distinct type that has object-like properties (as the PORT! type does) and could thus be acted upon by the appropriate Rebol actors (COPY/SKIP/NEXT/TAIL, etc.).</p>
<p><em>I've alluded to a similar idea in <a href="https://forum.rebol.info/t/semantics-of-port-s-vs-streams-vs-iterators/1689/4">an earlier post</a>, however this concept is more focussed on transcoding one series of numbers/characters to another. Filters are NOT scanners/tokenizers/lexers.</em></p>
<p>A filter source can be:</p>
<ul>
<li>BINARY! or TEXT! values</li>
<li>PORT! values that stream BINARY! or TEXT! (including files/network resources)</li>
<li>filter values (i.e. filters can be layered)</li>
</ul>
<p>Examples of filter types:</p>
<ul>
<li>Retrieves binary contained within a file/network resource</li>
<li>Decodes text encoded as UTF-8, UTF-16, ISO-8859-1, CP-1252, etc. (or even unspecified using something like Chardet)</li>
<li>Decodes binary compressed per Deflate, LZW, etc.</li>
<li>Decodes binary encoded as 'text' per Base64, Ascii85, Hexadecimal, etc.</li>
<li>Decrypts binary encrypted per e.g. Rebol 2 ENCLOAK/DECLOAK (but obviously more)</li>
<li>Decodes text encoded mostly literally but with escape sequences, e.g. JSON strings, Rebol strings, XML/HTML data sequences/attribute values</li>
</ul>
<p>Filters should have at least the following capabilities:</p>
<ul>
<li>Copy all encoded data</li>
<li>Copy part of the encoded data</li>
<li>Skip part of the encoded data (Deflate could potentially iterate faster if it wasn't emitting simultaneously)</li>
</ul>
<p>Filters should possibly have the following capabilities:</p>
<ul>
<li>BACK/HEAD/negative SKIP support</li>
<li>TAKE/REMOVE/CLEAR as a means of clearing buffers</li>
</ul>
<p>Functions that consume data should support filters as a pseudo-series type, e.g.</p>
<ul>
<li>Parse</li>
<li>BINARY/READ (from Oldes/Rebol3)</li>
<li>CONSUME (from <a href="https://forum.rebol.info/t/bincode/1863">rgchris/bincode</a>)</li>
</ul>
<p>Filter values are exhausted when:</p>
<ul>
<li>An end-of-content signal/delimiter has been found e.g. self-terminating formats such as Deflate; quote marks ending a JSON string</li>
<li>A filter cap has been reached e.g. the filter has a specified length</li>
<li>An unrecoverable error occurs (e.g. invalid UTF-8 sequences in strict mode; the 'g' character in a hexadecimal stream)</li>
<li>The source has been exhausted</li>
</ul>
<p>It should be possible to recover the current source at the corresponding index within a filter value though this may require additional state info, e.g. in Deflate or Base64 where a byte within an encoding has information pertaining to more than one decoded byte</p>
<p>Filter algorithms can be native (e.g. Deflate tied to Zlib, UTF-8) or in user-mode (thus extensible).</p>
          <p><a href="https://forum.rebol.info/t/concept-filters/2000/1">Read full topic</a></p>
        ]]></description>
        <link>https://forum.rebol.info/t/concept-filters/2000/1</link>
        <pubDate>Thu, 05 Jan 2023 03:49:47 +0000</pubDate>
        <guid isPermaLink="false">forum.rebol.info-post-2000-1</guid>
        <source url="https://forum.rebol.info/t/concept-filters/2000.rss">Concept: Filters</source>
      </item>
  </channel>
</rss>
