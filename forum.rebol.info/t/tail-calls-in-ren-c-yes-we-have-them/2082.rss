<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Tail Calls in Ren-C...Yes, We Have Them</title>
    <link>https://forum.rebol.info/t/tail-calls-in-ren-c-yes-we-have-them/2082</link>
    <description>Looking into some of [Joe Marshall&#39;s historical participation in Rebol](https://forum.rebol.info/t/the-sherman-rebol-to-scheme-compiler/2076), he speaks about Rebol 1.0 having &quot;continuations&quot; and &quot;tail calls&quot;.

Ren-C uses continuations to implement [stacklessness, based on a trampoline](https://forum.rebol.info/t/stackless-is-here-today-now/1844).  Trampolines are generally slower than the fiddly technique Joe describes Rebol 1.0 as having used--but such fiddly methods are not standard C, and do not translate well to WebAssembly.  In any case, the outcomes are similar.

Tail calls are a different feature.  But if you have continuations, then your code is likely structured in such a way that tail calls are not that difficult to add.

## So What Is A Tail Call?

When you invoke a function, the interpreter has to allocate some space for its arguments and locals.  This information is then associated with a stack level structure, which also takes some space... and is put in a chain representing the call stack.

If that function calls itself recursively, the recursion will also need new stack space for its arguments and locals...and another stack level structure.

With recursive algorithms where a function calls itself hundreds or thousands of times, you can use up a lot of memory (and/or generate a stack overflow).

Tail calls are based on the observation that right at the moment a function is about to return, it doesn&#39;t need its stack level or arguments/locals anymore.  So if you&#39;re willing to have your call stack suffer some amount of &quot;amnesia&quot; about the &quot;real&quot; stack depth, you can reuse the current call&#39;s stack level for a recursion.

## Ren-C Supports Explicit Tail Calls With RETURN:RUN

There are two forms of tail call we can do in a Rebol-like interpreter.  The first style can call any function (not just the one you&#39;re returning from).  It avoids a recursion level on the stack, but does *not* reuse the memory for arguments and locals.

This is what that looks like:

    foo: func [return: [tag!] n] [
        if n = 1 [
            return &lt;success&gt;
        ]
        return:run foo/ n - 1
    ]

    &gt;&gt; foo 100
    == &lt;success&gt;

That triggers 100 calls to FOO, but only using one level of stack depth.

There&#39;s a fairly obvious technical reason why this variation cannot build the invocation for the recursion&#39;s N into the old stack frame&#39;s N argument... *it uses the old N (as `n - 1`) to calculate the new N*.  You can&#39;t calculate new parameters into old parameter slots without winding up referencing your intermediate calculations instead of the old values you wanted.

*(A compiled language could notice when old arguments were used to calculate new ones, and if it happened they could make space for temporary copies just for values that would be overwritten before they were seen...but being interpreted, we have to assume the worst and keep all the old values.)*

If you really want to avoid making a new stack level *and* reuse the memory for the args and locals, you need a different approach.  Mutate the variables in-place before jumping to a restart of the function:

    foo: func [return: [tag!] n] [
        if n = 1 [
            return &lt;success&gt;
        ]
        n: n - 1
        return:run &#39;redo
    ]

    &gt;&gt; foo 100
    == &lt;success&gt;

Modifying the variables in place means you&#39;re responsible for any dependency issues.  If you overwrite one of your arguments while calculating the next, you wrote the code in sequence and you can see what you did.

## Why RETURN:RUN FOO/ vs. RETURN FOO or RERUN FOO

Ren-C&#39;s RETURN construct has special knowledge of what function it returns from.  It is a specialization of a generic DEFINITIONAL-RETURN function, which is specialized with the target FRAME!.  It&#39;s done in a somewhat optimized way, but still has some cost.

If tail calls were done with another construct--e.g. something like RERUN--that function would also need to be specialized with this knowledge.  It&#39;s cheaper to just piggy back on what RETURN already knows and make it a refinement.

As for why it has to take a trailing-slash PATH! vs. plain WORD! for the function to invoke...this is due to RETURN not taking its first argument literally.  So it&#39;s too late to intercept the mechanics of the call once an evaluation is run.  RETURN would receive the product of the call.

It winds up looking fairly natural, because the RUN construct runs a function that gathers its arguments inline does the same thing:

    &gt;&gt; run (either 1 &lt; 2 [append/] [insert/]) [a b c] [d e]
    == [a b c [d e]]

So if you were to RUN just a function, it would also look like RETURN:RUN...

    &gt;&gt; run append/ [a b c] [d e]
    == [a b c [d e]]

**Note that even if we could make tail calls implicit, we probably wouldn&#39;t want to.**  Python hasn&#39;t added tail calls at all, based on a philosophical objection to the idea of obscuring the call stack.  It also seems like if an algorithm depends on tail calls for some important optimization reason, there should be something to indicate that fact... so that someone reorganizing the code will be sensitive to it.

## How Important Are Tail Calls?

If your language has a very limited amount of stack, being able to formulate your code to use tail calls so it doesn&#39;t accrue stack could be very important.

But if your language has a decent amount of stack (or is completely &quot;stackless&quot;) it&#39;s not particularly important.

Where it matters are cases where an algorithm can be cleanly expressed in a recursive way, and you don&#39;t want to use an uglier representation that builds data structures which are mimicking what you would be getting naturally from the stack.

Using them in places that don&#39;t matter is likely just going to confuse your stack traces and error messages...like the Python people say.  I&#39;d discourage going around and changing all your RETURN SOMETHING to RETURN:RUN SOMETHING/ to try and speed things up.  Only do it if you&#39;re writing an algorithm that would have pathological stack use otherwise.</description>
    
    <lastBuildDate>Fri, 27 Dec 2024 08:01:39 +0000</lastBuildDate>
    <category>Functions</category>
    <atom:link href="https://forum.rebol.info/t/tail-calls-in-ren-c-yes-we-have-them/2082.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Tail Calls in Ren-C...Yes, We Have Them</title>
        <dc:creator><![CDATA[hostilefork]]></dc:creator>
        <description><![CDATA[
            <h2><a name="p-7990-returnrun-had-a-precursor-redo-1" class="anchor" href="https://forum.rebol.info#p-7990-returnrun-had-a-precursor-redo-1"></a>RETURN:RUN Had A Precursor... REDO</h2>
<p>The original formulation of tail calls wasn't built into RETURN, but expected you to work with a more generic tool called REDO.  This is what you had to write for the FOO example:</p>
<pre><code>foo: func [return: [tag!] n] [
    frame: binding of 'n
    if n = 0 [
        return &lt;success&gt;
    ]
    n: n - 1
    redo frame
]
</code></pre>
<p>This corresponds to the <strong><code>return:run 'redo</code></strong> variant, but that version takes advantage of the fact that RETURN already knows the frame it returns to, and can use that to redo.</p>
<p>REDO tried to have parity with that, by accepting a word from a frame and assuming you wanted to redo whatever that was bound to:</p>
<pre><code>foo: func [return: [tag!] n] [
    if n = 0 [
        return &lt;success&gt;
    ]
    n: n - 1
    redo $n
]
</code></pre>
<p>This had led me to say <em>"sure, Ren-C has tail calls"</em>.  But I realized that didn't really look like what people would expect, so I made RETURN:RUN.</p>
<p>An added benefit of RETURN:RUN is that if you use it with the function call form then it offers something that REDO couldn't do, which is reuse an internal <code>Level</code> structure for an arbitrary new function call.</p>
<h2><a name="p-7990-but-ive-realized-redo-was-fundamentally-broken-2" class="anchor" href="https://forum.rebol.info#p-7990-but-ive-realized-redo-was-fundamentally-broken-2"></a>But I've Realized REDO Was Fundamentally Broken...</h2>
<p>I've mentioned that I've been dotting "i's" and crossing "t's", so assertions are tightening up.  And this idea of generalized REDO--<em>regardless of what kind of action generator is in effect</em>--has a lot of holes in it.</p>
<p>Basically, your generator has to know it's being REDO'd and it has to come up with a semantically coherent meaning for that.  This is challenging, e.g. if you have a YIELDER.</p>
<pre><code>/y: yielder [yield: [integer!] x [integer!]] [
    yield x + 1
    yield x + 2
    redo binding of $yield
]

&gt;&gt; y 10
== 11

&gt;&gt; y 20
== 22

&gt;&gt; y 30
== 31  ; where's the magic to implement this?
</code></pre>
<p>There's a lot that goes into making yielder work, which is tracked in the Details array of the generated function.  That state is sensitive to the question of whether the yielder is "in flight" or not.  You can't just take an in-flight yielder and start running its C dispatcher code as if it's having its first execution, the whole thing dies.</p>
<h2><a name="p-7990-must-cooperate-with-the-generator-like-returnrun-3" class="anchor" href="https://forum.rebol.info#p-7990-must-cooperate-with-the-generator-like-returnrun-3"></a>Must Cooperate With The Generator, like RETURN:RUN</h2>
<p>If this kind of feature is going to be offered, it has to be offered with the generator's knowledge, so the right thing can be done.</p>
<p>If it were important, generalized REDO <em>could</em> be a general feature that is intercepted by function generators.  But designing that generalization does not make a whole lot of sense at this time, and I can't really see any time in the future for it either.</p>
<p>The formulation as a feature of something like RETURN or YIELD makes much more sense because that cooperative relationship is already established.</p>
<p>So, I'm killing off the broken REDO.  To the extent this unimportant feature is important at all, use <strong><code>return:run 'redo</code></strong></p>
<h2><a name="p-7990-old-redo-tests-4" class="anchor" href="https://forum.rebol.info#p-7990-old-redo-tests-4"></a>Old REDO Tests</h2>
<p>Here's what's going away.  (Analogous tests already exist for RETURN:RUN where applicable)</p>
<pre><code>; REDO via a direct FRAME! value
(
    /foo: func [return: [tag!] n] [
        let frame: binding of $n
        if n = 0 [
            return &lt;success&gt;
        ]
        n: n - 1
        redo frame
    ]

    &lt;success&gt; = foo 100
)

; REDO via extraction of FRAME! from an ANY-WORD?
; (has binding to a FRAME! to lookup variable value)
(
    /foo: func [return: [tag!] n] [
        if n = 0 [
           return &lt;success&gt;
        ]
        n: n - 1
        redo $n
    ]

    &lt;success&gt; = foo 100
)

; REDO locals clearing test
; (locals should be cleared on each redo)
(
    /foo: func [return: [tag!] n &lt;local&gt; unset-me] [
        if set? $unset-me [
            return "local not cleared"
        ]
        if n = 0 [
            return &lt;success&gt;
        ]
        n: n - 1
        unset-me: #some-junk
        redo $return
    ]

    &lt;success&gt; = foo 100
)

; REDO type checking test
; (args and refinements must pass function's type checking)
;
~expect-arg~ !! (
    /foo: func [return: [tag!] n i [integer!]] [
        if n = 0 [
            return &lt;success&gt;  ; impossible for this case
        ]
        n: n - 1
        i: #some-junk  ; type check should fail on redo
        redo $return
    ]

    foo 100 1020
)

; REDO phase test
; (shared frame compositions should redo the appropriate "phase")
(
    /inner: func [return: [tag!] n] [
        if n = 0 [
            return &lt;success&gt;
        ]
        n: 0
        redo $n  comment "should redo INNER, not outer"
    ]

    /outer: adapt inner/ [
        if n = 0 [
            return "outer phase run by redo"
        ]
        ; fall through to inner, using same frame
    ]

    &lt;success&gt; = outer 1
)

; !!! This initially seemed to have some broken expectations, that the OUTER
; would be able to view a variable (f.n) of INNER, when INNER does a redo of
; OUTER that does not also redo INNER...hence the frame is stale.  Not clear
; what the point was, but changed to count down a global to at least demo
; the ability to REDO an ENCLOSE frame.
(
    global: 1

    /inner: func [return: [text!] n :captured-frame [frame!]] [
        if n = 0 [
           return "inner phase run by redo"
        ]
        n: 0
        redo captured-frame  ; should redo OUTER, not INNER
    ]

    /outer: enclose inner/ func [return: [tag!] f] [
        if global = 0 [  ; was F.N, see note about that being wrong
            return &lt;success&gt;
        ]

        f.captured-frame: binding of $f
        global: me - 1

        ; Fall through to inner
        ; It is running in the same frame's memory, but...
        ; CAPTURED-FRAME is a FRAME! value that stowed outer's "phase"

        return eval-free f
    ]

    &lt;success&gt; = outer 1
)

; "Sibling" tail-call with compatible function
;
; (CHAINs are compatible with functions at head of CHAIN
;  ADAPTs are compatible with functions they adapt
;  SPECIALIZEs are compatible with functions they specialize...etc.)
;
; If LOG is set to DUMP the following will output:
;
;     --- C ---
;     n: =&gt; 11
;     delta: =&gt; 0
;     --- S ---
;     n: =&gt; 11
;     delta: =&gt; 10
;     --- BASE ---
;     n: =&gt; 11
;     delta: =&gt; 10
;     --- C ---
;     n: =&gt; 1
;     delta: =&gt; 10
;     --- S ---
;     n: =&gt; 1
;     delta: =&gt; 10
;     --- BASE ---
;     n: =&gt; 10
;     delta: =&gt; 10
;
; C is called and captures its frame into F.  Then it uses REDO:SIBLING to
; reuse the frame to call S.  S gets the variables and args that its knows
; about as C left them--such as N and a captured frame F--but values it takes
; for granted are reset, which includes specialized delta of 10.
;
; (The need to reset specializations for consistency is similar to how locals
; must be reset--they're not part of the interface of the function, so to
; reach beneath them does something illegal in terms of parameterization.)
;
; S doesn't have any effect besides resetting delta, so it falls through as
; an adaptation to the base function.  BASE subtracts DELTA from N to get 1,
; which isn't an exit condition.  The F frame which was set in C and was
; preserved as an argument to S is then used by BASE to REDO and get back
; up to the start of C again.
;
; Once again C captures its frame and does a REDO to start up S, which now
; notices that N is 1 so it bumps it up to 10.  (It cannot set DELTA to 1,
; because as a specialized argument DELTA is not visible to it.)  This time
; when it falls through to BASE, the subtraction of DELTA from N yields
; zero so that BASE returns completion.
;
; Since the function we originally called and built a frame for was a CHAIN,
; the REDO is effectively REDO-finishing the frame for the adaptation of
; BASE that sits at the head of the frame.  That delegation has now finished
; bouncing around on that single frame and come to a completion, which means
; the chained functions will get that result.  The string is translated to
; a tag and signals success.
(
    /log: (
        func ['x] []  comment "no-op"
        elide dump/  comment "un-elide to get output"
    )

    /base: func [return: [text!] n delta :captured-frame [frame!]] [
        log ["BASE" n delta]

        n: n - delta
        if n &lt; 0 [return "base less than zero"]
        if n = 0 [return "base done"]
        if captured-frame [redo captured-frame]
        return "base got no frame"
    ]

    /c: cascade [
        adapt base/ [
           log ["C" n delta]

           captured-frame: binding of $n
           redo:sibling $n s/

           comment "fall through to base"
        ]
        lambda [x] [
            if x = "base done" [
                &lt;success&gt;
            ] else [
                spaced ["base exited with" x]
            ]
        ]
    ]

    /s: specialize adapt base/ [
        log ["S" n delta]

        if n = 1 [n: 10]
    ][
        delta: 10
    ]

    &lt;success&gt; = c 11 0
)
</code></pre>
          <p><a href="https://forum.rebol.info/t/tail-calls-in-ren-c-yes-we-have-them/2082/2">Read full topic</a></p>
        ]]></description>
        <link>https://forum.rebol.info/t/tail-calls-in-ren-c-yes-we-have-them/2082/2</link>
        <pubDate>Fri, 27 Dec 2024 06:35:18 +0000</pubDate>
        <guid isPermaLink="false">forum.rebol.info-post-2082-2</guid>
        <source url="https://forum.rebol.info/t/tail-calls-in-ren-c-yes-we-have-them/2082.rss">Tail Calls in Ren-C...Yes, We Have Them</source>
      </item>
      <item>
        <title>Tail Calls in Ren-C...Yes, We Have Them</title>
        <dc:creator><![CDATA[hostilefork]]></dc:creator>
        <description><![CDATA[
            <p>Looking into some of <a href="https://forum.rebol.info/t/the-sherman-rebol-to-scheme-compiler/2076">Joe Marshall's historical participation in Rebol</a>, he speaks about Rebol 1.0 having "continuations" and "tail calls".</p>
<p>Ren-C uses continuations to implement <a href="https://forum.rebol.info/t/stackless-is-here-today-now/1844">stacklessness, based on a trampoline</a>.  Trampolines are generally slower than the fiddly technique Joe describes Rebol 1.0 as having used--but such fiddly methods are not standard C, and do not translate well to WebAssembly.  In any case, the outcomes are similar.</p>
<p>Tail calls are a different feature.  But if you have continuations, then your code is likely structured in such a way that tail calls are not that difficult to add.</p>
<h2><a name="p-6770-so-what-is-a-tail-call-1" class="anchor" href="https://forum.rebol.info#p-6770-so-what-is-a-tail-call-1"></a>So What Is A Tail Call?</h2>
<p>When you invoke a function, the interpreter has to allocate some space for its arguments and locals.  This information is then associated with a stack level structure, which also takes some space... and is put in a chain representing the call stack.</p>
<p>If that function calls itself recursively, the recursion will also need new stack space for its arguments and locals...and another stack level structure.</p>
<p>With recursive algorithms where a function calls itself hundreds or thousands of times, you can use up a lot of memory (and/or generate a stack overflow).</p>
<p>Tail calls are based on the observation that right at the moment a function is about to return, it doesn't need its stack level or arguments/locals anymore.  So if you're willing to have your call stack suffer some amount of "amnesia" about the "real" stack depth, you can reuse the current call's stack level for a recursion.</p>
<h2><a name="p-6770-ren-c-supports-explicit-tail-calls-with-returnrun-2" class="anchor" href="https://forum.rebol.info#p-6770-ren-c-supports-explicit-tail-calls-with-returnrun-2"></a>Ren-C Supports Explicit Tail Calls With RETURN:RUN</h2>
<p>There are two forms of tail call we can do in a Rebol-like interpreter.  The first style can call any function (not just the one you're returning from).  It avoids a recursion level on the stack, but does <em>not</em> reuse the memory for arguments and locals.</p>
<p>This is what that looks like:</p>
<pre><code>foo: func [return: [tag!] n] [
    if n = 1 [
        return &lt;success&gt;
    ]
    return:run foo/ n - 1
]

&gt;&gt; foo 100
== &lt;success&gt;
</code></pre>
<p>That triggers 100 calls to FOO, but only using one level of stack depth.</p>
<p>There's a fairly obvious technical reason why this variation cannot build the invocation for the recursion's N into the old stack frame's N argument... <em>it uses the old N (as <code>n - 1</code>) to calculate the new N</em>.  You can't calculate new parameters into old parameter slots without winding up referencing your intermediate calculations instead of the old values you wanted.</p>
<p><em>(A compiled language could notice when old arguments were used to calculate new ones, and if it happened they could make space for temporary copies just for values that would be overwritten before they were seen...but being interpreted, we have to assume the worst and keep all the old values.)</em></p>
<p>If you really want to avoid making a new stack level <em>and</em> reuse the memory for the args and locals, you need a different approach.  Mutate the variables in-place before jumping to a restart of the function:</p>
<pre><code>foo: func [return: [tag!] n] [
    if n = 1 [
        return &lt;success&gt;
    ]
    n: n - 1
    return:run 'redo
]

&gt;&gt; foo 100
== &lt;success&gt;
</code></pre>
<p>Modifying the variables in place means you're responsible for any dependency issues.  If you overwrite one of your arguments while calculating the next, you wrote the code in sequence and you can see what you did.</p>
<h2><a name="p-6770-why-returnrun-foo-vs-return-foo-or-rerun-foo-3" class="anchor" href="https://forum.rebol.info#p-6770-why-returnrun-foo-vs-return-foo-or-rerun-foo-3"></a>Why RETURN:RUN FOO/ vs. RETURN FOO or RERUN FOO</h2>
<p>Ren-C's RETURN construct has special knowledge of what function it returns from.  It is a specialization of a generic DEFINITIONAL-RETURN function, which is specialized with the target FRAME!.  It's done in a somewhat optimized way, but still has some cost.</p>
<p>If tail calls were done with another construct--e.g. something like RERUN--that function would also need to be specialized with this knowledge.  It's cheaper to just piggy back on what RETURN already knows and make it a refinement.</p>
<p>As for why it has to take a trailing-slash PATH! vs. plain WORD! for the function to invoke...this is due to RETURN not taking its first argument literally.  So it's too late to intercept the mechanics of the call once an evaluation is run.  RETURN would receive the product of the call.</p>
<p>It winds up looking fairly natural, because the RUN construct runs a function that gathers its arguments inline does the same thing:</p>
<pre><code>&gt;&gt; run (either 1 &lt; 2 [append/] [insert/]) [a b c] [d e]
== [a b c [d e]]
</code></pre>
<p>So if you were to RUN just a function, it would also look like RETURN:RUN...</p>
<pre><code>&gt;&gt; run append/ [a b c] [d e]
== [a b c [d e]]
</code></pre>
<p><strong>Note that even if we could make tail calls implicit, we probably wouldn't want to.</strong>  Python hasn't added tail calls at all, based on a philosophical objection to the idea of obscuring the call stack.  It also seems like if an algorithm depends on tail calls for some important optimization reason, there should be something to indicate that fact... so that someone reorganizing the code will be sensitive to it.</p>
<h2><a name="p-6770-how-important-are-tail-calls-4" class="anchor" href="https://forum.rebol.info#p-6770-how-important-are-tail-calls-4"></a>How Important Are Tail Calls?</h2>
<p>If your language has a very limited amount of stack, being able to formulate your code to use tail calls so it doesn't accrue stack could be very important.</p>
<p>But if your language has a decent amount of stack (or is completely "stackless") it's not particularly important.</p>
<p>Where it matters are cases where an algorithm can be cleanly expressed in a recursive way, and you don't want to use an uglier representation that builds data structures which are mimicking what you would be getting naturally from the stack.</p>
<p>Using them in places that don't matter is likely just going to confuse your stack traces and error messages...like the Python people say.  I'd discourage going around and changing all your RETURN SOMETHING to RETURN:RUN SOMETHING/ to try and speed things up.  Only do it if you're writing an algorithm that would have pathological stack use otherwise.</p>
          <p><a href="https://forum.rebol.info/t/tail-calls-in-ren-c-yes-we-have-them/2082/1">Read full topic</a></p>
        ]]></description>
        <link>https://forum.rebol.info/t/tail-calls-in-ren-c-yes-we-have-them/2082/1</link>
        <pubDate>Mon, 18 Dec 2023 03:58:16 +0000</pubDate>
        <guid isPermaLink="false">forum.rebol.info-post-2082-1</guid>
        <source url="https://forum.rebol.info/t/tail-calls-in-ren-c-yes-we-have-them/2082.rss">Tail Calls in Ren-C...Yes, We Have Them</source>
      </item>
  </channel>
</rss>
